---
title: "Homework5"
author: "Thomas Shi"
date: "2022/5/16"
output: html_document
---

```{r setup, include=FALSE}
library(janitor)
library(ggplot2)
library(dplyr)
library(tidymodels)
library(tidyverse)
library(Matrix)
library(glmnet)
```

1
```{r, echo = T}
poke <- read.csv("Pokemon.csv")
head(poke)
poke <- clean_names(poke)
head(poke)
```

The label of each feature changes. clean_names will make names only inculde _character, numbers and letters. It will make the column names more formatted and the data more organized


2
```{r, echo = T, fig.width = 10}
type_1 <- table(poke$type_1)
ggplot( data = poke, aes(x = type_1)) + geom_bar()
#There are 18 classes of pokemon
#There are one type of pokemon with very few numbers which is flying

pokemon <- poke %>% filter(type_1 == 'Bug' | type_1 == 'Fire' | type_1 == 'Grass' | type_1 == 'Normal' 
                | type_1 == 'Water' | type_1 == 'Psychic')

pokemon <- pokemon %>%
  mutate(type_1 = factor(type_1),
         legendary = factor(legendary))

head(pokemon)
```


3
```{r, echo = T}
pokemon_split <- pokemon %>% 
  initial_split(strata = type_1, prop = 0.7)
pokemon_train <- training(pokemon_split)
pokemon_test <- testing(pokemon_split)
dim(pokemon_train)
dim(pokemon_test)
#There are 318 individuals in testing set and 140 individuals in training set
#The sample sizes will be enough for both sets

set.seed(13)
pokemon_folds <- vfold_cv(pokemon_train, v = 5, strata = type_1)
pokemon_folds
```

If we stratify the folds, each fold will have similar distribution as the training set, so the mean response value will be roughly equal to each other. Each fold will be representative of all strata of the data. Each class will be approximately equally represented across each fold.



4
```{r, echo = T}
pokemon_recipe <- recipe(type_1 ~ legendary + generation + sp_atk + attack + speed + defense + hp , 
                         data = pokemon_train)

pokemon_recipe <- pokemon_recipe %>% step_dummy(legendary, generation)
pokemon_recipe <- pokemon_recipe %>% step_center(all_predictors())
pokemon_recipe <- pokemon_recipe %>% step_scale(all_predictors())

pokemon_recipe
```


5
```{r, echo = T}
elastic_net <- 
  multinom_reg(penalty = tune(), mixture = tune()) %>% 
  set_mode("classification") %>% 
  set_engine("glmnet")

elastic_workflow <- workflow() %>% 
  add_recipe(pokemon_recipe) %>% 
  add_model(elastic_net)

penalty_grid <- grid_regular(penalty(range = c(-5, 5)), mixture(range = c(0,1)), levels = 10)
penalty_grid
```

Totally, 500 models will be fitted. The combination between penalty and mixture is 100 and there is five folds.


6
```{r, echo = T, fig.height = 8}
tune_res <- tune_grid(
  elastic_workflow,
  resamples = pokemon_folds, 
  grid = penalty_grid
)

tune_res

autoplot(tune_res)
```

Both ROC AUC and accuracy will first increase until about 0.02 and then start to decrease

For accuracy, smaller mixture values tend to perform better. For ROC AUC, higher mixture values give the best RUC AUC. As penalty increase, ROC AUC with smaller mixture values will decrease slower.


7
```{r, echo = T}
best_penalty <- select_best(tune_res, metric = "roc_auc")
best_penalty

elastic_final <- finalize_workflow(elastic_workflow, best_penalty)

elastic_final_fit <- fit(elastic_final, data = pokemon_train)

augment(elastic_final_fit, new_data = pokemon_test) %>%
  accuracy(truth = type_1, estimate = .pred_class)

```

The accuracy of the model is 0.3857


8
```{r, echo = T}
augment(elastic_final_fit, new_data = pokemon_test) %>%
  roc_auc(truth = type_1, .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Water, .pred_Psychic)

augment(elastic_final_fit, new_data = pokemon_test) %>%
  roc_curve(type_1, .pred_Bug, .pred_Fire, .pred_Grass, .pred_Normal, .pred_Water, .pred_Psychic) %>%
  autoplot()

augment(elastic_final_fit, new_data = pokemon_test) %>%
  conf_mat(truth = type_1, estimate = .pred_class) %>% 
  autoplot(type = "heatmap")
```

The model doesn't perform well, the accuracy is low. ROC shows that the performance is poor. Normal type pokemon is the model best at predicting. Fire type and Grass type are the model worst at predicting. Maybe, the information contained in the features are not helpful for determining the type of pokemon, or, maybe, the model is not appropriate for this data set. 





